d = melt(incident_cases %>%
filter(Country.Region %in%c("Italy", "France", "United Kingdom", "Germany", "Spain", "Japan", "Sweden"), Province.State == "") %>%
select(- c("Lat", "Long", "UID", "FIPS", "Province.State", "County")), id.vars = c( "Country.Region"))
d$time = as.Date(d$variable)
d$value = sapply(d$value, function(x){as.numeric(x)})
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/smoothed_incidence_plots_7days.pdf")
k=1
library(reshape2)
theme_set(theme_bw())
d = melt(data %>%
filter(Country.Region %in%c("Italy", "France", "United Kingdom", "Germany", "Spain", "Japan", "Sweden"), Province.State == "") %>%
select(- c("Lat", "Long", "UID", "FIPS"), "County"), id.vars = c("Province.State", "Country.Region"))
d$time = as.Date(d$variable)
d$value = sapply(d$value, function(x){as.numeric(x)})
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/cumulative_plots.pdf")
#### Oki so what we have is the nmber of total (cumulative cases)
incident_cases = data
incident_cases[,5] = NA
incident_cases[,6:(ncol(data)-3)] = t(apply(data[,5:(ncol(data)-3)], 1, function(x){diff(as.numeric(x))}))
d = melt(incident_cases %>%
filter(Country.Region %in%c("Italy", "France", "United Kingdom", "Germany", "Spain", "Japan", "Sweden"), Province.State == "") %>%
select(- c("Lat", "Long", "UID", "FIPS", "County","Province.State")), id.vars = c( "Country.Region"))
d$time = as.Date(d$variable)
d$value = sapply(d$value, function(x){as.numeric(x)})
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/raw_incidence_plots.pdf")
ggplot(d %>% filter(time > as.Date("2020/07/01"))) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/raw_incidence_plots_recent.pdf")
### Transform the incident cases:
k = 1
incident_cases[,(6+k):(ncol(data)-3 - k)] = sapply((6+k):(ncol(data)-3 - k), function(i){ apply(incident_cases[,(i-k):(i+k)], 1, function(x){round(mean(x))})
})
incident_cases[,(6+k):(ncol(data)-3 - k)][which(incident_cases[,(6+k):(ncol(data)-3 - k)] <0, arr.ind = TRUE)] = 0
d = melt(incident_cases %>%
filter(Country.Region %in%c("Italy", "France", "United Kingdom", "Germany", "Spain", "Japan", "Sweden"), Province.State == "") %>%
select(- c("Lat", "Long", "UID", "FIPS", "Province.State", "County")), id.vars = c( "Country.Region"))
d$time = as.Date(d$variable)
d$value = sapply(d$value, function(x){as.numeric(x)})
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/smoothed_incidence_plots_3days.pdf")
ggplot(d %>% filter(Province.State == "", time > as.Date("2020/07/01"))) +
geom_point(aes(x = time, y=value, colour = Province.State))
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region), size=3)
ggsave("~/Downloads/smoothed_incidence_plots_3days.pdf")
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region), size=2)
ggsave("~/Downloads/smoothed_incidence_plots_3days.pdf")
incident_cases = data
incident_cases[,5] = NA
incident_cases[,6:(ncol(data)-3)] = t(apply(data[,5:(ncol(data)-3)], 1, function(x){diff(as.numeric(x))}))
d = melt(incident_cases %>%
filter(Country.Region %in%c("Italy", "France", "United Kingdom", "Germany", "Spain", "Japan", "Sweden"), Province.State == "") %>%
select(- c("Lat", "Long", "UID", "FIPS", "County","Province.State")), id.vars = c( "Country.Region"))
d$time = as.Date(d$variable)
d$value = sapply(d$value, function(x){as.numeric(x)})
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region))
ggsave("~/Downloads/raw_incidence_plots.pdf")
ggplot(d) +
geom_point(aes(x = time, y=value, colour = Country.Region), size=2)
ggsave("~/Downloads/raw_incidence_plots.pdf")
shiny::runApp('Dropbox/COVID-app')
runApp('Dropbox/COVID-app')
runApp('Dropbox/COVID-app')
runApp('Dropbox/COVID-app')
runApp('Dropbox/COVID-app')
runApp('Dropbox/COVID-app')
shiny::runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
shiny::runApp('Dropbox/COVID-app2')
lengthseq((from=0, to=1, by=0.025))
length(seq((from=0, to=1, by=0.025))
length(seq(from=0, to=1, by=0.025))
length(seq(from=0, to=1, by=0.025))
help("tabPanel")
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
help("HTML")
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
help("quantile")
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
print("oui")
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
runApp('Dropbox/COVID-app2')
# set parameters
g <- 4 # number of groups
n <- 5 # number of people per group
p <- c(.1, .2, .3, .4) # infection probability per group (could put a probability distribution, for now just specifying values)
x <- 5 # number of people to infect in population
# construct dataframe
id <- seq(1, g*n, by = 1) # individual ID
group <- rep(1:g, each = n) # assign group numbers
prob_infect <- rep(p, each = n) # assign infection probabilities
infected <- rep(0, g*n) # infection status: 1 = infected; 0 = not infected
data <- as.data.frame(cbind(id, group, prob_infect, infected))
# randomly select individuals to infect
i <- sample(data$id, size = x)
data$infected[i] <- 1 # change infection status
# set parameters
g <- 4 # number of groups
n <- 50 # number of people per group
p <- c(.1, .2, .3, .4) # infection probability per group (could put a probability distribution, for now just specifying values)
x <- 5 # number of people to infect in population
# construct dataframe
id <- seq(1, g*n, by = 1) # individual ID
group <- rep(1:g, each = n) # assign group numbers
prob_infect <- rep(p, each = n) # assign infection probabilities
infected <- rep(0, g*n) # infection status: 1 = infected; 0 = not infected
data <- as.data.frame(cbind(id, group, prob_infect, infected))
# randomly select individuals to infect
i <- sample(data$id, size = x)
data$infected[i] <- 1 # change infection status
View(data)
source("functions.R")
source("~/Dropbox/Group-testing/functions.R")
Se <- 0.95
Sp <- 0.95
#Order statistics for individual probabilities
p.a0.1 <- beta.dist(p = 0.05, a = 0.1, grp.sz = 5)
p.a0.1
help(dbeta)
CRC.a0.1 <- get.CRC(p = p.a0.1, se = Se, sp = Sp, stages = 3)
CRC.a0.1
prob_infect
CRC.a0.1 <- get.CRC(p = prob_infect, se = Se, sp = Sp, stages = 3)
CRC.a0.1$ET
CRC.a0.1
CRC.a0.1$I2
CRC.a0.1$I1
CRC.a0.1
ORC.a0.1 <- get.CRC(p = prob_infect, se = Se, sp = Sp, everycase = TRUE, stages = 3)
CRC.a0.1$I2
p.a0.1 <- beta.dist(p = 0.05, a = 0.1, grp.sz = 200)
p.a0.1
install.packages("binGroup")
library(binGroup)
OTC("D2", p = NULL, probabilities = p, Se = 0.99, Sp = 0.99, group.sz =10, weights = NULL, alpha = 2)
OTC("D2", p = NULL, probabilities = p, Se = 0.99, Sp = 0.99, group.sz =2-0, weights = NULL, alpha = 2)
OTC("D2", p = NULL, probabilities = p, Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
p
prob_infect
OTC("D2", p = NULL, probabilities = prob_infect , Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
OTC("D2", p = NULL, probabilities = NULL , Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
test = OTC("D2", p = 12/200, probabilities = NULL , Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
test$prob
test$opt.ET
test = OTC("D2", p = 12/200, probabilities = NULL , Se = 0.99, Sp = 0.99, group.sz =10, weights = NULL, alpha = 2)
test$opt.ET
test
test = OTC("ID2", p = 12/200, probabilities = prob_infect , Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
test = OTC("ID2", probabilities = prob_infect , Se = 0.99, Sp = 0.99, group.sz =200, weights = NULL, alpha = 2)
test = OTC("ID2", probabilities = prob_infect , Se = 0.99, Sp = 0.99, group.sz =10, weights = NULL, alpha = 2)
test = OTC("ID2", probabilities = prob_infect[1:10] , Se = 0.99, Sp = 0.99, group.sz =10, weights = NULL, alpha = 2)
test
test = OTC("ID2", probabilities = prob_infect , Se = 0.99, Sp = 0.99, group.sz =10, weights = NULL, alpha = 2)
suppressPackageStartupMessages({
require(httr)
require(readr)
require(dplyr)
require(tidyr)
require(lubridate)
require(padr)
})
.args <- if (interactive()) c(
"somedata.csv"
) else commandArgs(trailingOnly = TRUE)
rawthing <- GET(
"https://opendata.ecdc.europa.eu/covid19/casedistribution/csv",
authenticate(":", ":", type="ntlm")
)$content
allDat <- read_csv(rawthing)
# filter, etc
# munging data into correct format and selecting countries with greater than 10 deaths
allTogetherClean <- allDat %>%
arrange(countriesAndTerritories, dateRep) %>%
mutate(dateRep = dmy(dateRep))%>%
rename(date = dateRep, new_cases = cases, new_deaths = deaths, country = countriesAndTerritories, country_code = countryterritoryCode) %>%
select(date, country, country_code, new_cases, new_deaths) %>%
filter(!country %in% c("CANADA", "Cases_on_an_international_conveyance_Japan")) %>%
group_by(country) %>%
pad() %>%
mutate(new_cases = replace_na(new_cases, 0),
new_deaths = replace_na(new_deaths, 0)) %>%
group_by(country) %>%
mutate(cum_deaths = sum(new_deaths)) %>%
filter(cum_deaths > 0) %>%
select(-cum_deaths) %>%
mutate(new_cases = case_when(new_cases < 0 ~ 0,
new_cases >= 0 ~ new_cases),
new_deaths = case_when(new_deaths < 0 ~ 0,
new_deaths >= 0 ~ new_deaths)
)
install.packages("padr")
require(padr)
# filter, etc
# munging data into correct format and selecting countries with greater than 10 deaths
allTogetherClean <- allDat %>%
arrange(countriesAndTerritories, dateRep) %>%
mutate(dateRep = dmy(dateRep))%>%
rename(date = dateRep, new_cases = cases, new_deaths = deaths, country = countriesAndTerritories, country_code = countryterritoryCode) %>%
select(date, country, country_code, new_cases, new_deaths) %>%
filter(!country %in% c("CANADA", "Cases_on_an_international_conveyance_Japan")) %>%
group_by(country) %>%
pad() %>%
mutate(new_cases = replace_na(new_cases, 0),
new_deaths = replace_na(new_deaths, 0)) %>%
group_by(country) %>%
mutate(cum_deaths = sum(new_deaths)) %>%
filter(cum_deaths > 0) %>%
select(-cum_deaths) %>%
mutate(new_cases = case_when(new_cases < 0 ~ 0,
new_cases >= 0 ~ new_cases),
new_deaths = case_when(new_deaths < 0 ~ 0,
new_deaths >= 0 ~ new_deaths)
)
allTogetherClean
source('~/Dropbox/Group-testing/SCedit_PooledTestingModel_101320_basecase_statistics.R')
source('~/Dropbox/Group-testing/SCedit_PooledTestingModel_101320_basecase_statistics.R')
install.packages("DescTools")
source('~/Dropbox/Group-testing/SCedit_PooledTestingModel_101320_basecase_statistics.R')
source('~/Dropbox/Group-testing/SCedit_PooledTestingModel_101320_basecase_statistics.R')
tests %>% filter(result == "positive", firsttest==TRUE,!is.na(cttarget)) %>% pull(cttarget) -> cts
cts
plotdist(cts, histo = TRUE, demp = TRUE, breaks=18)
descdist(cts, boot = 1000)
fw <- fitdist(cts, "weibull")
fw
fno <- fitdist(cts, "norm")
fg <- fitdist(cts, "gamma")
fln <- fitdist(cts, "lnorm")
# Plot fit distributions and generate goodness-of-fit statistics
par(mfrow = c(2, 2))
plot.legend <- c("weibull","normal","gamma", "lnorm")
denscomp(list(fw,fno,fg,fln), legendtext = plot.legend,xlim=c(0,50),breaks=25)
qqcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
cdfcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
ppcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
gofstat(list(fw,fno,fg,fln))
summary(fw)
# Number of replicates to generate ecdf offset values for above.
set.seed(42)
x<-50000
# Determine ct value quantiles for real first tests vs. fitted Weibull distribution
quantile(cts,c(0.5,0.25,0.75,0.95,0.99))
quantile(fw,c(0.5,0.25,0.75,0.95,0.99))
cts
fw
quantile(fw,c(0.5,0.25,0.75,0.95,0.99))
ct_fake_input <- rweibull(x,fw[[1]][1],fw[[1]][2])
lod <- 35
above.lod <- seq(0.05,0.3,0.05)
sequence <- seq(-10,15,0.01)
mat<-matrix(ncol=3,nrow=length(sequence)*length(lod))
above.lod
sequence
length(sequence)
v=1
help(ecdf)
lod[i]
1:length(lod)
subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45)
help("subsetting")
help(subset)
length(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45))
length(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<35))
length(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<32))
length(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<32))
sequence[v]
length(subset(pmax(5,ct_fake_input),(pmax(5,ct_fake_input))<32))
length(subset(pmax(5,ct_fake_input),(pmax(5,ct_fake_input))<45))
length(subset(pmax(5,ct_fake_input),(pmax(5,ct_fake_input))<lod))
1-fn(lod[i])
mat<-matrix(ncol=3,nrow=length(sequence)*length(lod))
for(v in 1:length(sequence)){
fn<-ecdf(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45))
for(i in 1:length(lod)){
a<-1-fn(lod[i])
mat[(v-1)*length(lod)+i,1]<-lod[i]
mat[(v-1)*length(lod)+i,2]<-a
mat[(v-1)*length(lod)+i,3]<-sequence[v]
}
}
# Shif
mat2<-matrix(ncol=3,nrow=length(lod)*length(above.lod))
for(i in 1:length(lod)){
for(j in 1:length(above.lod)){
tmp<-subset(mat,mat[,1]==lod[i])
u<-tmp[which.min(abs(above.lod[j]-tmp[,2])),3]
mat2[(i-1)*length(above.lod)+j,1]<-lod[i]
mat2[(i-1)*length(above.lod)+j,2]<-above.lod[j]
mat2[(i-1)*length(above.lod)+j,3]<-u
}
}
mat2
probit_input <- read.csv("probit_zscores_cts_tissue_agnostic.csv")
probit_t<-subset(probit_input,probit_input$z_value<=1.96 & probit_input$z_value>=-1.96)
probit<-probit_t[,c(2,4,3)]
probit<-probit[order(probit$z_value,probit$ct_value),]
z_scores<-as.numeric(unlist(distinct(probit,z_value)))
# Number of replicates for model
set.seed(42)
n <- 10000
pool.max<-20
probit.mode<-c("base","dsa.lower","dsa.upper","psa")
probit.mode.index<-1 # 1 = no variation, 2, = LLN, 3 = ULN, 4 = probabilistic
probit.z.indices<-c(488,1,length(z_scores)) # 488 is a z score of 0 (base case) in the z index vector
dilution.vary.index<-1 # 1 = no variation, 2 = probabilistic
c(488,1,length(z_scores))
as.numeric(unlist(distinct(probit,z_value)))
1:length(above.lod)
# Changing "lod" itself has no effect on model output.
lod <- 35
above.lod <- seq(0.05,0.3,0.05)
sequence <- seq(-10,15,0.01)
mat<-matrix(ncol=3,nrow=length(sequence)*length(lod))
for(v in 1:length(sequence)){
fn<-ecdf(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45))
for(i in 1:length(lod)){
a<-1-fn(lod[i])
mat[(v-1)*length(lod)+i,1]<-lod[i]
mat[(v-1)*length(lod)+i,2]<-a
mat[(v-1)*length(lod)+i,3]<-sequence[v]
}
}
# Shift ct values for each lod and %above lod
mat2<-matrix(ncol=3,nrow=length(lod)*length(above.lod))
for(i in 1:length(lod)){
for(j in 1:length(above.lod)){
tmp<-subset(mat,mat[,1]==lod[i])
u<-tmp[which.min(abs(above.lod[j]-tmp[,2])),3]
mat2[(i-1)*length(above.lod)+j,1]<-lod[i]
mat2[(i-1)*length(above.lod)+j,2]<-above.lod[j]
mat2[(i-1)*length(above.lod)+j,3]<-u
}
}
# probit data input
probit_input <- read.csv("probit_zscores_cts_tissue_agnostic.csv")
probit_t<-subset(probit_input,probit_input$z_value<=1.96 & probit_input$z_value>=-1.96)
probit<-probit_t[,c(2,4,3)]
probit<-probit[order(probit$z_value,probit$ct_value),]
z_scores<-as.numeric(unlist(distinct(probit,z_value)))
# Number of replicates for model
set.seed(42)
n <- 10000
pool.max<-20
probit.mode<-c("base","dsa.lower","dsa.upper","psa")
probit.mode.index<-1 # 1 = no variation, 2, = LLN, 3 = ULN, 4 = probabilistic
probit.z.indices<-c(488,1,length(z_scores)) # 488 is a z score of 0 (base case) in the z index vector
dilution.vary.index<-1 # 1 = no variation, 2 = probabilistic
# Model loop, vary % above each LOD
for (llod in 1:length(lod)){
allfirst.poolct <- data.table::rbindlist(lapply(1:length(above.lod),function(above) {
ct_set<-pmax(5,subset(ct_fake_input+mat2[(llod-1)*length(above.lod)+above,3],
ct_fake_input+mat2[(llod-1)*length(above.lod)+above,3]<45))
threshold.ct <- c(sample(ct_set,n,replace=T))
data.table::rbindlist(lapply(1:pool.max, function (p) { # pool size
data.table::rbindlist(lapply(c(0.001,0.01,0.03,0.05,0.1,0.15), function(prevalence) { # proportion positive tests
data.table::rbindlist(lapply(0:p, function(positives) {
if (positives == 0) data.frame(limit=lod[llod], pool=p, pos=positives, prevalence=prevalence, above.llod = above.lod[above],
concentration=0, probability = dbinom(positives, p, prevalence), random=0, z.index=0, call.each.conc=FALSE, tests=1, tn=1,tp=0,fn=0,fp=0)
else {
dat <- matrix(sample(threshold.ct, positives * n, replace=T), nrow=positives) # sample data uniformly at random - introduce correlation structure here
each.conc = -log2(colSums(2^-dat)/p)+ifelse(dilution.vary.index==1,0,rnorm(mean=0,sd=1.1,n=ncol(dat))) # sd of 1.1 reflects confidence interval for deviation from perfect log2 dilution in assays
data.frame(
limit=lod[llod],
pool=p,
pos=positives,
prevalence=prevalence,
above.llod=above.lod[above],
concentration=each.conc,
probability = dbinom(positives, p, prevalence)/n,
random=sample(n,n)/n,
z.index=ifelse(probit.mode.index<4,probit.z.indices[probit.mode.index],sample(1:length(z_scores),n,replace=T))) %>%
mutate(
call.each.conc=probit[1+(z.index-1)*571+each.conc*10-(lod[llod]-35.9)*10,2]>random,
tests=1 + p * (call.each.conc),
tn=0,
tp=1 * (call.each.conc),
fn=1 * (!call.each.conc),
fp=0)
}
}))
}))
}))
}))
group_by(allfirst.poolct, pool, prevalence, above.llod, limit) %>%
summarize(pos=weighted.mean(pos, w=probability),
total.tests=weighted.mean(tests, w=probability),
tests.per.sample=weighted.mean(tests, w=probability)/mean(pool),
tn=weighted.mean(tn, w=probability),
tp=weighted.mean(tp, w=probability),
fn=weighted.mean(fn, w=probability),
fp=weighted.mean(fp, w=probability)) -> apw
rm(allfirst.poolct)
tmp <- as.data.frame(apw)
ifelse(llod==1,all<-apw,all<-rbind(all,tmp))
rm(tmp)
rm(apw)
}
v
v=1
fn<-ecdf(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45))
fn
lod[i]
1-fn(lod[i])
mat
mat[2500,]
j=1
subset(mat,mat[,1]==lod[i])
above.lod[j]
above.lod[j]
tmp[,2]
which.min(abs(above.lod[j]-tmp[,2]))
above.lod[j]
tmp[which.min(abs(above.lod[j]-tmp[,2])),]
above.lod[j]
z_scores
sequenc[v]
sequence[length(sequence)]
sequence
length(sequence)
sequence[length(sequence)]
subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45)
length(subset(pmax(5,ct_fake_input+sequence[v]),(pmax(5,ct_fake_input+sequence[v]))<45))
length(subset(pmax(5,ct_fake_input- sequence[v]),(pmax(5,ct_fake_input-sequence[v]))<45))
length(subset(pmax(5,ct_fake_input + sequence[v]),(pmax(5,ct_fake_input+ sequence[v]))<45))
length(subset(pmax(5,ct_fake_input + sequence[v]),(pmax(5,ct_fake_input+ sequence[v]))<45))
v=-10
subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45)
length(subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45))
v=15
length(subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45))
v=10
length(subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45))
v=019
v=-10
length(subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45))
v=15
length(subset(pmax(5,ct_fake_input+v),(pmax(5,ct_fake_input+v))<45))
# probit data input
probit_input <- read.csv("probit_zscores_cts_tissue_agnostic.csv")
probit_t<-subset(probit_input,probit_input$z_value<=1.96 & probit_input$z_value>=-1.96)
probit<-probit_t[,c(2,4,3)]
probit<-probit[order(probit$z_value,probit$ct_value),]
z_scores<-as.numeric(unlist(distinct(probit,z_value)))
help("pmax")
ct_set
llod=1
above=1
shift = mat2[(llod-1)*length(above.lod)+above,3]
shift
pmax(5,subset(ct_fake_input+shift,
ct_fake_input+shift<45))
n
c(sample(ct_set,n,replace=T))
